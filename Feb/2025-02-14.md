## 날짜: 2025-02-14


### 오늘 학습한 내용

## 딥다이브 진행
### 주제별 정리

1. 데이터 분석 전에 수행해야 하는 전처리 과정과 데이터 품질을 향상시키는 방법을 설명하시오. @lillian.rhee(이채언) 
    - 데이터 전처리는 데이터의 결측치와 이상치 등의 원본 데이터의 문제를 해결하고 데이터의 복잡성과 계산 효율성을 개선하는 작업이며, 품질을 향상 시키는 방법은 다양하다


2. 정형 데이터와 비정형 데이터를 처리하는 기술의 차이점과 각각의 실용 사례를 설명하시오. @timmy.park(박정민)/인공지능 
    - 정형데이터는 RDBS에 저장하기전 Pandas를 활용한 전처리가 필수이며 자동화를 통하여 시간을 정략할수 있다
    - 비정형 데이터는 Json, yaml을 통한 모델설정및 API처리가 핵심이다
    - re.sub를 통하여 데이터 정제 과정이 중요하며, 인코딩 변환및 파일변환 작업도 효율적으로 처리하는것이 필요하다

3. SciPy를 활용한 기본 통계 분석이 데이터 해석에 어떤 도움을 주는지 설명하시오. @민선 
    - Scipy를 통한 기본 통계분석은 데이터의 중심 경향, 분포, 상관관계, 가설 검정 등을 수행하여 데이터의 특성을 효과적으로 파악하는 데 도움을 주며, 이룰통해 정규성 검정, 회귀분석 등을 활용하여 데이터 기반 의사 결정을 보다 신뢰성 있게 할 수 있다 

4. 시각화 도구를 활용한 데이터의 통찰 전달 방법을 설명하시오. @woody.lee(이동재) 
    - 데이터 시각화는 복잡한 데이터를 분석하는데 용이하고, 다양한 표현이 가능하다.
    - 표현 방법으로 사용할 수 있는 방법이 많으니 선택해서 사용하면 된다.
    - 데이터 시각화를 통해 처음 접하는 사람에게도 시각적으로 데이터에 대해 소통이 가능하다.    
    
5. 시계열 데이터 분석이 데이터를 시간 기반으로 이해하는 데 중요한 이유를 설명하시오. @mac.lee(이원호) 
    - 시간의 흐름 별로 데이터를 분류하여 패턴을 알아낼수 있다.(계절성 및 트랜드)
    - 이상치(outlier)를 탐지하여 급격한 변화를 알아낼수 있다.
    - 이동평균기법 (SMA,EMA,WMA 등) 사용하여 추세흐름을 파악할수 있다.
    - 다른 시계열 간의 비교로 상관관계를 분석하여 인과관계를 알 수 있다.
    - ‘ARIMA’와 같은 시계열 분석 기법을 통해 예측 모델링 설계가 가능하다!
    
6. 데이터 리모델링 패키지를 활용해 데이터를 변환하고 집계하는 방법을 설명하시오. @yuju(최병현) 
    
 - **데이터 리모델링의 정의**
    - 데이터를 분석하기 쉬운 형태로 변환하는 과정
    - 데이터 품질 향상과 분석 효율성 증대가 목적
- **주요 작업 영역**
    1. 데이터 변환: 형태와 구조 변경
    2. 데이터 집계: 통계적 계산과 요약
    3. 데이터 정제: 결측값, 중복값 처리


### Void 특강
- Chat GPT를 잘 활용하여 딥다이브를 하자
- 대화를 하기전 프롬프트 엔지니어링을 통하여 대화하자
- 전문지식에는 아직 부정확성이 있을수 있으니 지속적인 새로운 대화로 오류를 최소화 시키자
- 자신이 어느정도의 깊이까지 가야하는지는 자신의 실력에 따라 다르다

## 오늘의 회고
- 딥다이브를 진행할시 GPT를 쓰긴 하였지만 프롬프트를 사용하는것이 아닌 지속적인 대화를 통하여 개선하였기에 효율적으로 사용해보고자 한다



