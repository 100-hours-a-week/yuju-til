## 날짜: 2025-02-17


### 오늘 학습한 내용

## SciPy & 통계적 시각화 복습및 미니 퀘스트 풀기
### Scipy를 쓰는 이유는 무엇인가?
- 데이터 보간 및 정제
- 노이즈 제거 및 신호 필터링
- 고급 수학적 변환 적용
- 곡선 피팅 및 회귀 분석



#### 사용 방법
1. 최적화 (Optimization) - 함수 최솟값 찾기
    - SciPy의 `scipy.optimize` 모듈을 사용하면 수학적 함수의 최솟값을 구할 수 있습니다.

2. 통계 분석 (Statistics) - 정규 분포 생성 및 분석
    - SciPy의 `scipy.stats` 모듈을 사용하면 다양한 확률 분포를 생성하고 분석할 수 있습니다.   

3. 신호 처리 (Signal Processing) - 푸리에 변환 (FFT)
    - SciPy의 `scipy.fft` 모듈을 사용하면 주어진 신호를 주파수 도메인으로 변환할 수 있습니다.

4. 수치 적분 (Integration) - 정적분 계산
    - SciPy의 `scipy.integrate` 모듈을 사용하면 수치 적분을 수행할 수 있습니다.

5. 선형 대수 (Linear Algebra) - 행렬 연산 및 고유값 분해
    - SciPy의 `scipy.linalg` 모듈을 사용하면 행렬 연산 및 고유값 분해를 수행할 수 있습니다.

### 정규 분포(Normal Distribution)

#### **정규 분포의 특징**

정규 분포는 평균(μ)과 표준 편차(σ)에 의해 결정되는 확률 분포이며, 데이터가 평균을 중심으로 분포하는 중요한 통계적 모델입니다.

다음은 정규 분포의 주요 특징입니다.

| **특징** | **설명** |
| --- | --- |
| **평균(μ)을 중심으로 좌우 대칭** | 데이터가 평균을 기준으로 대칭적으로 분포하며, 평균보다 작은 값과 큰 값이 동일한 확률을 가집니다. |
| **데이터의 68-95-99.7 법칙** | - 약 `68%`의 데이터가 `μ ± 1σ` 범위 내에 위치합니다.
- 약 `95%`의 데이터가 `μ ± 2σ` 범위 내에 위치합니다.
- 약 `99.7%`의 데이터가 `μ ± 3σ` 범위 내에 위치합니다. |
| **표준 편차(σ)에 따라 분포 형태가 결정됨** | 표준 편차가 작으면 분포가 좁고 뾰족해지며, 크면 넓고 완만해집니다. |
| **데이터가 평균 근처에 집중됨** | 평균에서 멀어질수록 확률이 급격히 감소하며, 극단적인 값이 발생할 가능성이 낮아집니다. |
| **여러 통계 기법에서 기본 가정으로 사용됨** | 가설 검정, 회귀 분석, 주성분 분석(PCA) 등에서 데이터가 정규 분포를 따른다고 가정하는 경우가 많습니다. |

#### 사용방법
1. 정규 분포 데이터 생성 및 확인
    - `data = np.random.normal(loc=50, scale=10, size=1000)`: 평균 `50`, 표준 편차 `10`인 정규 분포에서 `1000`개의 난수를 생성

2. 정규 분포의 확률 밀도 함수(PDF) 시각화
    - `sns.histplot(data, bins=30, kde=True, color="skyblue", alpha=0.7)`: 히스토그램을 그리며 커널 밀도 추정(kde)을 추가하고 색상을 `skyblue`, 투명도를 `0.7`로 설정

3. 특정 값의 확률 밀도 계산 (PDF 활용)
    - `pdf_value = stats.norm.pdf(x_value, loc=50, scale=10)`: 평균 `50`, 표준편차 `10`인 정규 분포에서 `x=55`의 확률 밀도 함수(PDF) 값을 계산

4. 특정 값 이하의 누적 확률 계산 (CDF 활용)
    - `cdf_value = stats.norm.cdf(x_value, loc=50, scale=10)`: 평균 `50`, 표준편차 `10`인 정규분포에서 `x_value` 이하의 누적 확률을 계산

5. 분위수 계산 (PPF 활용)
    - `quantile_90 = stats.norm.ppf(0.90, loc=50, scale=10)`: 평균 `50`, 표준편차 `10`인 정규분포에서 누적 확률 `90%`일 때의 분위수를 계산

6. 정규 분포를 활용한 이상값 탐지
    - `lower_bound = 50 - 2 * 10`: 평균 `50`에서 `2`배의 표준 편차 `10`을 뺀 값을 이상값 하한으로 설정
    - `upper_bound = 50 + 2 * 10`: 평균 `50`에서 `2`배의 표준 편차 `10`을 더한 값을 이상값 상한으로 설정
    - `outliers = data[(data < lower_bound) | (data > upper_bound)]`: 데이터에서 하한보다 작거나 상한보다 큰 값을 이상값으로 선택
    - `print(f"이상값 개수: {len(outliers)}")`: 이상값의 개수를 출력

### 기술 통계(Descriptive Statistics)
#### **기술 통계의 핵심 지표**

1. **중앙 경향성 (Central Tendency)**
    
    
    | 구분 | 설명 |
    | --- | --- |
    | **평균(Mean)** | 데이터 값의 합을 데이터 개수로 나눈 값으로, 대표적인 중심 경향성 지표입니다. |
    | **중앙값(Median)** | 데이터를 정렬했을 때 가운데 오는 값으로, 이상값(Outlier)의 영향을 덜 받습니다. |
    | **최빈값(Mode)** | 데이터에서 가장 빈도수가 높은 값으로, 자료의 대표적인 특성을 보여줍니다. |
2. **산포도 (Dispersion)**
    
    
    | 구분 | 설명 |
    | --- | --- |
    | **범위(Range)** | 최댓값과 최솟값의 차이를 통해 자료가 퍼져 있는 정도를 간단히 확인합니다. |
    | **분산(Variance)** | 데이터 값들이 평균에서 얼마나 떨어져 있는지를 수치화한 지표로, 값이 클수록 변동성이 큽니다. |
    | **표준 편차(Standard Deviation)** | 분산의 제곱근으로, 데이터의 평균적 변동성을 직관적으로 파악하는 데 쓰입니다. |
    | **사분위 범위(IQR)** | 1사분위수(Q1)와 3사분위수(Q3)의 차이로, 데이터 중간 영역의 퍼짐 정도를 나타냅니다. |
3. **분포 특성 (Distribution Characteristics)**
    
    
    | 구분 | 설명 |
    | --- | --- |
    | **왜도(Skewness)** | 분포의 비대칭성을 나타내는 값입니다.
    0보다 크면 오른쪽으로 치우친 분포(양의 왜도), 0보다 작으면 왼쪽으로 치우친 분포(음의 왜도)를 뜻합니다. |
    | **첨도(Kurtosis)** | 분포가 뾰족한 정도로, 3보다 크면 정규 분포보다 뾰족한 분포(급첨), 3보다 작으면 평평한 분포(완만)를 의미합니다. |

#### 사용방법
1. 데이터 준비 및 확인
    - `data = np.random.normal(loc=50, scale=10, size=100)`: 평균 `50`, 표준 편차 `10`을 따르는 정규 분포에서 난수 `100`개를 생성
    - `df = pd.DataFrame(data, columns=["value"])`: 생성한 데이터를 Pandas 데이터프레임으로 변환하고 열 이름을 `"value"`로 설정

2. 기본적인 기술 통계 계산 (describe())
    - `summary = df.describe()`: 데이터프레임의 기술 통계량(평균, 표준편차, 최솟값, 최댓값 등)을 계산

3. 개별 기술 통계 지표 계산 (SciPy 활용)
    - `mean_value = np.mean(df["value"])`: `"value"` 열의 평균을 계산
    - `median_value = np.median(df["value"])`: `"value"` 열의 중앙값을 계산
    - `mode_value = stats.mode(df["value"], keepdims=True).mode[0]`: `"value"` 열의 최빈값을 계산 (SciPy 최신 버전 대응)
    - `std_dev = np.std(df["value"], ddof=1)`: `"value"` 열의 표준 편차를 계산 (`ddof=1`로 자유도 적용)
    - `variance = np.var(df["value"], ddof=1)`: `"value"` 열의 분산을 계산 (`ddof=1`로 자유도 적용)
    - `data_range = np.ptp(df["value"])`: `"value"` 열의 범위를 계산 (최댓값 - 최솟값)
    - `q1 = np.percentile(df["value"], 25)`: `"value"` 열의 1사분위수(Q1)를 계산
    - `q3 = np.percentile(df["value"], 75)`: `"value"` 열의 3사분위수(Q3)를 계산
    - `iqr = q3 - q1`: 사분위 범위(IQR)를 계산 (`Q3 - Q1`)
    - `skewness = stats.skew(df["value"])`: `"value"` 열의 왜도를 계산
    - `kurtosis = stats.kurtosis(df["value"])`: `"value"` 열의 첨도를 계산
    - `print(f"평균: {mean_value}")`: 평균을 출력
    - `print(f"중앙값: {median_value}")`: 중앙값을 출력
    - `print(f"최빈값: {mode_value}")`: 최빈값을 출력
    - `print(f"표준 편차: {std_dev}")`: 표준 편차를 출력
    - `print(f"분산: {variance}")`: 분산을 출력
    - `print(f"범위: {data_range}")`: 범위를 출력
    - `print(f"IQR (사분위 범위): {iqr}")`: 사분위 범위를 출력
    - `print(f"왜도: {skewness}")`: 왜도를 출력
    - `print(f"첨도: {kurtosis}")`: 첨도를 출력

4. 이상값(Outlier) 탐지
    - `lower_bound = q1 - 1.5 * iqr`: IQR을 이용하여 하한 경계값을 계산
    - `upper_bound = q3 + 1.5 * iqr`: IQR을 이용하여 상한 경계값을 계산
    - `outliers = df[(df["value"] < lower_bound) | (df["value"] > upper_bound)]`: 값이 하한 또는 상한 경계를 벗어난 데이터를 선택
    - `print("이상값 개수:", len(outliers))`: 이상값 개수를 출력
    - `print(outliers.reset_index())`: 이상값 데이터를 인덱스를 초기화하여 출력

5. 기본 시각화: 히스토그램 (Histogram)
    - `sns.histplot(df["value"], bins=15, kde=True, color="skyblue", alpha=0.6)`: `df["value"]` 데이터를 기반으로 `bins=15`개의 구간을 가진 히스토그램을 생성하고 KDE 곡선을 추가하며 색상을 `"skyblue"`, 투명도를 `0.6`으로 설정

### 가설 검정(Hypothesis Testing)

| **개념** | **설명** | **그래프에서의 위치** |
| --- | --- | --- |
| **귀무가설 (H₀)** | 귀무가설은 기본적으로 참이라고 가정하는 가설로, 연구자가 반증하고자 하는 대상입니다.
예를 들어, "새로운 치료법은 기존 치료법과 효과 차이가 없다"라는 가정이 이에 해당합니다.
쉽게 말해, "특별한 변화가 없다"고 보는 것입니다. | 검은색 곡선 (Null Distribution, H₀ is True)으로 표시되어 있으며,
귀무가설이 참일 때의 검정 통계량 분포를 나타냅니다. |
| **대립가설 (H₁)** | 대립가설은 검정하고자 하는 가설로, 귀무가설과 반대되는 주장입니다.
예를 들어, "새로운 치료법이 기존 치료법보다 효과적이다"라고 주장하는 것이 대립가설입니다.
즉, "변화가 있다" 또는 "차이가 있다"고 보는 것입니다. | 회색 점선 곡선 (Alternative Distribution, H₁ is True)으로 표시되어 있으며,
대립가설이 참일 때의 검정 통계량 분포를 나타냅니다. |
| **1종 오류 (Type I Error)** | 1종 오류는 실제로 귀무가설이 참인데, 이를 잘못 기각하는 오류입니다.
쉽게 말해, "효과가 없는데 있다고 착각하는 실수"입니다.
예를 들어, "실제로 약이 효과가 없는데 효과가 있다고 결론을 내리는 경우"입니다. | 빨간색 음영 영역 (Rejection Region, α)으로 표시되어 있으며,
귀무가설이 참일 때 검정 통계량이 이 영역에 속하면 기각됩니다. |
| **2종 오류 (Type II Error)** | 2종 오류는 실제로 대립가설이 참인데, 귀무가설을 기각하지 않는 오류입니다.
쉽게 말해, "효과가 있는데 없다고 판단하는 실수"입니다.
예를 들어, "실제로 약이 효과가 있는데 효과가 없다고 결론을 내리는 경우"입니다. | 파란색 음영 영역 (Type II Error, β)으로 표시되어 있으며,
대립가설이 참일 때 검정 통계량이 이 영역에 속하면 기각되지 않습니다. |

#### **가설 검정의 주요 유형**

가설 검정에는 다양한 유형이 있으며, 비교하는 데이터의 성격과 분석 목적에 따라 검정 방법이 달라집니다.

평균 비교, 독립성 검정, 분산 분석, 회귀 분석 등 여러 유형이 있으며, 각 검정 방법은 특정한 연구 질문을 해결하는 데 사용됩니다.

| **검정 종류** | **설명** |
| --- | --- |
| **단일 표본 t-검정
(One-Sample t-test)** | 한 그룹의 평균이 특정 값과 다른지 검정합니다.
- `예:` "한 도시의 평균 키가 170cm와 다른가?" |
| **독립 표본 t-검정
(Independent t-test)** | 두 그룹의 평균 차이를 검정합니다.
- `예:` "남성과 여성의 평균 체온이 같은가?" |
| **대응 표본 t-검정
(Paired t-test)** | 동일한 그룹의 전/후 변화를 비교합니다.
- `예:` "운동 프로그램 전후 체중 변화가 있는가?" |
| **카이제곱 검정
(Chi-Square Test)** | 범주형 변수 간 독립성을 검정합니다.
- `예:` "흡연과 폐암 발병률 사이에 연관이 있는가?" |
| **ANOVA
(분산 분석, Analysis of Variance)** | 세 개 이상의 그룹 간 평균 차이를 검정합니다.
- `예:` "세 개의 학급 간 시험 성적 차이가 존재하는가?" |
| **회귀 분석
(Regression Analysis)** | 한 변수(X)가 다른 변수(Y)에 미치는 영향을 검정합니다.
- `예:` "광고비가 매출에 미치는 영향이 있는가?" |


#### 사용방법
1. 데이터 준비 및 확인
    - `group_A = np.random.normal(loc=50, scale=10, size=30)`: 평균 `50`, 표준 편차 `10`을 가지는 정규 분포에서 데이터 `30`개를 생성
    - `group_B = np.random.normal(loc=55, scale=10, size=30)`: 평균 `55`, 표준 편차 `10`을 가지는 정규 분포에서 데이터 `30`개를 생성
    - `df = pd.DataFrame({"Group A": group_A, "Group B": group_B})`: 그룹 A와 그룹 B 데이터를 포함하는 데이터프레임을 생성

2. 독립 표본 t-검정 (Independent t-test) 수행
    - `t_stat, p_value = stats.ttest_ind(group_A, group_B)`: 두 그룹 `group_A`와 `group_B`에 대한 독립 표본 t-검정을 수행
    - `print(f"t-통계량: {t_stat}")`: t-검정의 검정 통계량(t-statistic)을 출력
    - `print(f"p-값: {p_value}")`: t-검정의 유의확률(p-value)을 출력

3. 가설 검정을 활용한 데이터 시각화
    - `sns.boxplot(data=[group_A, group_B], palette=["skyblue", "salmon"])`: 두 그룹의 데이터를 박스 플롯으로 시각화하고 색상을 `skyblue`와 `salmon`으로 지정
